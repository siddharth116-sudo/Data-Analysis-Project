from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# Helper function to evaluate and visualize model performance.
def evaluate_model(pipeline, X_test, y_test, show_plots=True):
    y_pred = pipeline.predict(X_test)
    if hasattr(pipeline, "predict_proba"):
        y_score = pipeline.predict_proba(X_test)[:,1]
    else:
        try:
            y_score = pipeline.decision_function(X_test)
        except:
            y_score = None

    print(classification_report(y_test, y_pred, digits=4))
    if y_score is not None:
        roc = roc_auc_score(y_test, y_score)
        ap = average_precision_score(y_test, y_score)
        print(f"ROC AUC: {roc:.4f}  |  PR-AUC (avg precision): {ap:.4f}")

    # Display a confusion matrix to show true/false positives/negatives.
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(4,3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve to visualize the trade-off between true positive rate and false positive rate.
    if y_score is not None:
        fpr, tpr, _ = roc_curve(y_test, y_score)
        plt.figure(figsize=(5,4))
        plt.plot(fpr, tpr, label=f"AUC = {roc:.3f}")
        plt.plot([0,1],[0,1],'k--')
        plt.xlabel("FPR"); plt.ylabel("TPR"); plt.title("ROC curve"); plt.legend()
        plt.show()

# Baseline 1: Logistic Regression model.
pipe_lr = Pipeline(steps=[('pre', preprocessor),
                          ('clf', LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42))])
pipe_lr.fit(X_train, y_train)
print("Logistic Regression evaluation:")
evaluate_model(pipe_lr, X_test, y_test)

# Baseline 2: Random Forest model.
pipe_rf = Pipeline(steps=[('pre', preprocessor),
                          ('clf', RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42, n_jobs=-1))])
pipe_rf.fit(X_train, y_train)
print("Random Forest evaluation:")
evaluate_model(pipe_rf, X_test, y_test)