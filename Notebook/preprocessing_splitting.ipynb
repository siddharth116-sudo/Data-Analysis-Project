import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

# Create a copy of the DataFrame for preprocessing.
df2 = df.copy()

# Encode the target variable 'Placement' into a binary format (0 for 'No', 1 for 'Yes').
target_col = 'Placement'
df2[target_col] = df2[target_col].map({'No':0, 'Yes':1})

# Drop the 'College_ID' column as it is not a useful feature for the model.
if 'College_ID' in df2.columns:
    df2 = df2.drop(columns=['College_ID'])

# Re-identify numeric and categorical columns after dropping 'College_ID'.
num_cols = df2.select_dtypes(include=[np.number]).columns.tolist()
if target_col in num_cols:
    num_cols.remove(target_col)
cat_cols = df2.select_dtypes(include=['object','category']).columns.tolist()

print("Final num cols:", num_cols)
print("Final cat cols:", cat_cols)

# Define a pipeline for numeric features: impute missing values with the median and scale the data.
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Define a pipeline for categorical features: impute missing values with the most frequent value and one-hot encode them.
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# Use ColumnTransformer to apply the appropriate transformations to each column type.
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, num_cols),
        ('cat', categorical_transformer, cat_cols)
    ],
    remainder='drop'
)

# Separate the features (X) and the target variable (y).
X = df2.drop(columns=[target_col])
y = df2[target_col].astype(int)

# Split the data into 80% for training and 20% for testing.
# The 'stratify' parameter ensures that the proportion of 'Yes' and 'No' placements is the same in both sets.
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

print("Train shapes:", X_train.shape, y_train.shape)
print("Test shapes:", X_test.shape, y_test.shape)